{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b1caee6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "182ab4df",
      "metadata": {},
      "outputs": [],
      "source": [
        "from modules.d3pm.dit import DDiT_Llama\n",
        "\n",
        "# Model configuration\n",
        "N = 27  # text8 has 26 letters + 1 for padding/special token (vocab size)\n",
        "dim = 256\n",
        "n_layers = 6\n",
        "n_heads = 8\n",
        "multiple_of = 256\n",
        "ffn_dim_multiplier = None\n",
        "norm_eps = 1e-5\n",
        "learn_gating = False\n",
        "\n",
        "# Instantiate model\n",
        "model = DDiT_Llama(\n",
        "    N=N,\n",
        "    dim=dim,\n",
        "    n_layers=n_layers,\n",
        "    n_heads=n_heads,\n",
        "    multiple_of=multiple_of,\n",
        "    ffn_dim_multiplier=ffn_dim_multiplier,\n",
        "    norm_eps=norm_eps,\n",
        "    learn_gating=learn_gating\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b24a39a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 7,769,627\n",
            "Trainable parameters: 7,769,627\n"
          ]
        }
      ],
      "source": [
        "# Print number of parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {num_params:,}\")\n",
        "print(f\"Trainable parameters: {num_trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abda5ee8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([4, 128])\n",
            "Output shape: torch.Size([4, 128, 27])\n",
            "\n",
            "Original (as text):\n",
            "  Sample 0: 'the quick brown fox jumps over the lazy dog the qu...'\n",
            "  Sample 1: 'dog the quick brown fox jumps over the lazy dog th...'\n",
            "  Sample 2: 'azy dog the quick brown fox jumps over the lazy do...'\n",
            "  Sample 3: 'he lazy dog the quick brown fox jumps over the laz...'\n",
            "\n",
            "Masked Input (as text, '_' = masked):\n",
            "  Sample 0: 'the_quic__b_own_fox_jumps___er__he_laz___og_t___qu...'\n",
            "  Sample 1: 'dog_the_quic__brown_fox_jumps_over_the_laz___og_th...'\n",
            "  Sample 2: 'az__dog_the_quick_br____fox_jumps_over__he_lazy_do...'\n",
            "  Sample 3: 'he_laz__dog_th__q_ick__ro_n_fox_jum_s_ov_r_the_laz...'\n",
            "\n",
            "Output (as text, argmax of logits):\n",
            "  Sample 0: 'the quic  b own fox jumps   er  he laz   og t   qu...'\n",
            "  Sample 1: 'dog the quic  brown fox jumps over the laz   og th...'\n",
            "  Sample 2: 'az  dog the quick br    fox jumps over  he lazy do...'\n",
            "  Sample 3: 'he laz  dog th  q ick  ro n fox jum s ov r the laz...'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create dummy inputs for forward pass\n",
        "batch_size = 4\n",
        "seq_len = 128\n",
        "x = torch.randint(0, N, (batch_size, seq_len))  # Input token indices\n",
        "t = torch.randint(0, 1000, (batch_size,))  # Diffusion timesteps\n",
        "\n",
        "# Character mapping for text8 (a-z = 0-25, space = 26)\n",
        "chars = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# Sample from dataset and mask random positions\n",
        "# Note: Using a simple placeholder dataset for now (will use text8_indices after loading)\n",
        "# For demonstration, create a simple dataset from repeated alphabet\n",
        "sample_text = \"the quick brown fox jumps over the lazy dog \" * 20\n",
        "sample_indices = torch.tensor([chars.index(c) for c in sample_text[:seq_len * batch_size]], dtype=torch.long)\n",
        "sample_indices = sample_indices.view(batch_size, seq_len)\n",
        "\n",
        "# Mask a percentage of random positions\n",
        "mask_percent = 0.15  # 15% of positions will be masked\n",
        "mask_token = N - 1  # Use last token index as mask token (or could use a special value)\n",
        "\n",
        "# Create random mask\n",
        "mask = torch.rand(batch_size, seq_len) < mask_percent\n",
        "x = sample_indices.clone()\n",
        "x[mask] = mask_token  # Replace masked positions with mask token\n",
        "\n",
        "# Run forward pass\n",
        "with torch.no_grad():\n",
        "    output = model(x, t)\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "    \n",
        "    # Convert original indices to text\n",
        "    original_text = [''.join([idx_to_char.get(idx.item(), '?') for idx in seq]) for seq in sample_indices]\n",
        "    print(f\"\\nOriginal (as text):\")\n",
        "    for i, txt in enumerate(original_text):\n",
        "        print(f\"  Sample {i}: '{txt[:50]}...'\")\n",
        "    \n",
        "    # Convert masked input indices to text (show masked positions as '_')\n",
        "    input_text = [''.join(['_' if idx.item() == mask_token else idx_to_char.get(idx.item(), '?') for idx in seq]) for seq in x]\n",
        "    print(f\"\\nMasked Input (as text, '_' = masked):\")\n",
        "    for i, txt in enumerate(input_text):\n",
        "        print(f\"  Sample {i}: '{txt[:50]}...'\")\n",
        "    \n",
        "    # Convert output logits to text (argmax to get predicted tokens)\n",
        "    output_indices = output.argmax(dim=-1)\n",
        "    output_text = [''.join([idx_to_char.get(idx.item(), '?') for idx in seq]) for seq in output_indices]\n",
        "    print(f\"\\nOutput (as text, argmax of logits):\")\n",
        "    for i, txt in enumerate(output_text):\n",
        "        print(f\"  Sample {i}: '{txt[:50]}...'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c40998",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text8 dataset size: 100000000 characters\n",
            "Sample:  anarchism originated as a term of abuse first used against early working class radicals including t\n",
            "Text8 indices shape: torch.Size([100000000])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# Download text8 dataset\n",
        "data_dir = \"data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "text8_path = os.path.join(data_dir, \"text8\")\n",
        "if not os.path.exists(text8_path):\n",
        "    zip_path = os.path.join(data_dir, \"text8.zip\")\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(\"Downloading text8 dataset...\")\n",
        "        urllib.request.urlretrieve(\"http://mattmahoney.net/dc/text8.zip\", zip_path)\n",
        "    print(\"Extracting...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    os.remove(zip_path)\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"Text8 dataset already exists, skipping download.\")\n",
        "\n",
        "# Load text8 data\n",
        "with open(text8_path, 'r') as f:\n",
        "    text8_data = f.read()\n",
        "\n",
        "print(f\"Text8 dataset size: {len(text8_data)} characters\")\n",
        "print(f\"Sample: {text8_data[:100]}\")\n",
        "\n",
        "# Create character to index mapping (a-z = 0-25, space = 26)\n",
        "chars = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "\n",
        "# Convert text to indices\n",
        "text8_indices = torch.tensor([char_to_idx[c] for c in text8_data], dtype=torch.long)\n",
        "print(f\"Text8 indices shape: {text8_indices.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "985526e4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sequences: 390625\n",
            "Train sequences: 351562\n",
            "Test sequences: 39063\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Create train/test splits\n",
        "# We'll split the text8 data into sequences of length seq_len\n",
        "# Use 90% for training, 10% for testing\n",
        "\n",
        "# First, we need to wait for text8_indices to be loaded (cell 4)\n",
        "# For now, define the split function that will be used after loading\n",
        "\n",
        "seq_len = 256  # Length of each sequence\n",
        "\n",
        "# Reshape text8_indices into sequences\n",
        "num_sequences = len(text8_indices) // seq_len\n",
        "text8_sequences = text8_indices[:num_sequences * seq_len].view(num_sequences, seq_len)\n",
        "\n",
        "# Split into train/test (90/10)\n",
        "train_size = int(0.9 * num_sequences)\n",
        "train_sequences = text8_sequences[:train_size]\n",
        "test_sequences = text8_sequences[train_size:]\n",
        "\n",
        "print(f\"Total sequences: {num_sequences}\")\n",
        "print(f\"Train sequences: {len(train_sequences)}\")\n",
        "print(f\"Test sequences: {len(test_sequences)}\")\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = TensorDataset(train_sequences)\n",
        "test_dataset = TensorDataset(test_sequences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f78ed851",
      "metadata": {},
      "source": [
        " ---\n",
        " **Cosine schedule:**\n",
        " \n",
        " Cosine-style keep mass:\n",
        " \n",
        " $$ \\bar{\\alpha}_t = \\varepsilon + (1 - \\varepsilon) \\cos^2 \\left( \\frac{\\pi}{2} \\frac{t}{T} \\right) $$\n",
        " \n",
        " Then again:\n",
        " \n",
        " $$ \\beta_t = 1 - \\frac{\\bar{\\alpha}_t}{\\bar{\\alpha}_{t-1}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1044b45e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_schedule(T, eps=1e-4):\n",
        "    \"\"\"\n",
        "    Cosine noise schedule for diffusion models.\n",
        "    \n",
        "    Computes:\n",
        "        alpha_bar_t = eps + (1 - eps) * cos^2(pi/2 * t/T)\n",
        "        beta_t = 1 - alpha_bar_t / alpha_bar_{t-1}\n",
        "        alpha_t = 1 - beta_t\n",
        "    \n",
        "    Args:\n",
        "        T: number of timesteps\n",
        "        eps: small constant to prevent alpha_bar from reaching 0\n",
        "    \n",
        "    Returns:\n",
        "        betas: tensor of shape (T,) with beta values\n",
        "        alphas: tensor of shape (T,) with alpha values\n",
        "        alpha_bars: tensor of shape (T,) with cumulative alpha values\n",
        "    \"\"\"\n",
        "    # TODO: Create timestep indices from 0 to T-1\n",
        "    t = np.arange(0, T)\n",
        "    \n",
        "    # TODO: Compute alpha_bar_t = eps + (1 - eps) * cos^2(pi/2 * t/T)\n",
        "    alpha_bar_t = eps + (1 - eps) * np.cos(np.pi / 2 * t / T) ** 2\n",
        "    \n",
        "    # TODO: Compute beta_t = 1 - alpha_bar_t / alpha_bar_{t-1}\n",
        "    # Hint: Handle t=0 case separately (beta_0 = 1 - alpha_bar_0)\n",
        "    alpha_bar_t_prev = np.roll(alpha_bar_t, 1)\n",
        "    beta_t = 1 - alpha_bar_t / alpha_bar_t_prev\n",
        "    beta_t[0] = 1 - alpha_bar_t[0]\n",
        "    \n",
        "    # TODO: Clamp betas to valid range [0, 1)\n",
        "    beta_t = np.clip(beta_t, 0, 1)\n",
        "    \n",
        "    # Compute alpha_t = 1 - beta_t\n",
        "    alpha_t = 1 - beta_t\n",
        "    \n",
        "    # TODO: Return betas, alphas, and alpha_bars\n",
        "    return beta_t, alpha_t, alpha_bar_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ce1342",
      "metadata": {},
      "source": [
        " ---\n",
        "\n",
        " **Absorbing transition kernel**:\n",
        "\n",
        " For $k \\neq MASK$:\n",
        " $$ Q_t[k,j] = (1-\\beta_t) \\mathbf{1}[j=k] + \\beta_t \\cdot \\mathbf{1}[j=\\text{MASK}] $$\n",
        "\n",
        " For $k = MASK$:\n",
        " $$ Q_t[MASK, j] = 1[j=MASK] $$\n",
        "\n",
        " *Stationary distribution:*\n",
        "  $$ \\pi = \\delta_{MASK} \\quad (\\pi_{MASK}=1,\\; \\pi_k=0\\;\\text{for } k\\neq MASK). $$\n",
        " \n",
        "  > **Note:** $\\delta_{MASK}$ is the **Dirac delta distribution** centered at the MASK token—a \"one-hot\" vector where all probability mass is on the MASK state. This makes sense because the absorbing kernel always transitions tokens toward MASK and never leaves MASK once reached, so at equilibrium, everything ends up in the MASK state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "95826904",
      "metadata": {},
      "outputs": [],
      "source": [
        "def absorbing_kernel(beta_t, K, mask_token=None):\n",
        "    \"\"\"\n",
        "    Compute the absorbing transition matrix Q_t for D3PM.\n",
        "\n",
        "    The absorbing kernel transitions tokens to a special MASK token with probability beta_t,\n",
        "    and stays in place with probability (1 - beta_t). Once in the MASK state, it stays there.\n",
        "\n",
        "    For k != MASK:\n",
        "        Q_t[k, j] = (1 - beta_t) * 1[j=k] + beta_t * 1[j=MASK]\n",
        "\n",
        "    For k = MASK:\n",
        "        Q_t[MASK, j] = 1[j=MASK]\n",
        "\n",
        "    Args:\n",
        "        beta_t: Noise level at timestep t (scalar, 0 < beta_t < 1)\n",
        "        K: Number of discrete states/tokens (vocabulary size, including MASK token)\n",
        "        mask_token: Index of the MASK token (default: K-1, the last token)\n",
        "\n",
        "    Returns:\n",
        "        Q_t: Transition matrix of shape [K, K] where Q_t[k, j] = P(x_t = j | x_{t-1} = k)\n",
        "              Each row sums to 1.\n",
        "        pi: Stationary distribution of shape [K] (delta at MASK)\n",
        "    \"\"\"\n",
        "    # Set default mask_token to K-1 if not provided\n",
        "    if mask_token is None:\n",
        "        mask_token = K - 1\n",
        "\n",
        "    Q_t = np.zeros((K, K))\n",
        "\n",
        "    # TODO: : Implement transition rule\n",
        "    # [1-β   0    0   ...  β ]\n",
        "    # [ 0   1-β   0   ...  β ]\n",
        "    # [ 0    0   1-β  ...  β ]\n",
        "    # ...\n",
        "    # [ 0    0    0   ...  1 ]\n",
        "\n",
        "    # - For non-MASK tokens stay in place with probability (1 - beta_t): Q_t[k, k] = (1 - beta_t)\n",
        "    idx = np.arange(K)\n",
        "    non_mask = idx != mask_token\n",
        "    Q_t[idx[non_mask], idx[non_mask]] = 1 - beta_t\n",
        "\n",
        "    # - For MASK tokens transition to MASK with probability beta_t: Q_t[k, MASK] = beta_t\n",
        "    Q_t[idx[non_mask], idx[mask_token]] = beta_t\n",
        "\n",
        "    # - For MASK token stays in MASK state with probability 1 (0 otherwise)\n",
        "    Q_t[mask_token, idx[non_mask]] = 0\n",
        "    Q_t[mask_token, idx[mask_token]] = 1\n",
        "\n",
        "    # TODO: Create stationary distribution pi = delta_{MASK} of being in each state K\n",
        "    pi = np.zeros(K)\n",
        "    pi[mask_token] = 1\n",
        "\n",
        "    # TODO: Return the transition matrix Q_t and stationary distribution pi\n",
        "    return Q_t, pi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8473d39",
      "metadata": {},
      "source": [
        "  ---\n",
        "\n",
        "  **Training Steps for D3PM:**\n",
        "  1. Sample a batch of clean data $x_0$ from the dataset\n",
        "  2. Sample random timesteps $t \\sim \\text{Uniform}(1, T)$ for each sample in the batch\n",
        "  3. Corrupt $x_0$ to $x_t$ using the cumulative transition matrix $\\bar{Q}_t$: $p(x_t | x_0) = x_0 \\cdot \\bar{Q}_t$\n",
        "  4. Pass $x_t$ and $t$ to the model to predict $p(x_0 | x_t)$\n",
        "  5. Compute cross-entropy loss between predicted $x_0$ distribution and true $x_0$\n",
        "  6. Backpropagate and update model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f1cd3f89",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(model, x_0, optimizer, time_steps, Q, Q_bar, device):\n",
        "    \"\"\"\n",
        "    Single training step for D3PM (Discrete Denoising Diffusion Probabilistic Model).\n",
        "\n",
        "    In D3PM, we work with discrete tokens instead of continuous values.\n",
        "    The forward process corrupts discrete states using transition matrices Q.\n",
        "\n",
        "    Args:\n",
        "        model: The D3PM model that predicts p(x_0 | x_t)\n",
        "        x_0: Clean discrete tokens from dataset [batch_size, seq_len] (integer values 0 to K-1)\n",
        "        optimizer: The optimizer\n",
        "        time_steps: Total number of diffusion steps T\n",
        "        Q: Transition matrices for each timestep [T, K, K] where Q[t, i, j] = p(x_t=j | x_{t-1}=i)\n",
        "        Q_bar: Cumulative transition matrices [T, K, K] where Q_bar[t] = Q_1 @ Q_2 @ ... @ Q\n",
        "        device: Device to run on\n",
        "\n",
        "    Returns:\n",
        "        loss value\n",
        "    \"\"\"\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch_size = x_0.shape[0]\n",
        "    K = Q_bar.shape[-1]\n",
        "\n",
        "    # TODO: Sample a batch of random timesteps t ~ Uniform(1, T)\n",
        "    t = torch.randint(1, time_steps, (batch_size,), device=x_0.device)\n",
        "\n",
        "    # TODO: Compute corrupted tokens x_t by sampling from categorical distribution\n",
        "    # p(x_t | x_0) = x_0 @ Q_bar_t (one-hot x_0 times transition matrix) [B, S, K]\n",
        "    # Hint 1: Convert x_0 to one-hot probability distribution\n",
        "    # Hint 2.1: To multiply by Q_bar_t use torch.einsum for efficent BMM\n",
        "    # Hint 2.2: we multiply prob distribution x_0 by transition matrix Q_bar to get a prob distribution over x_t\n",
        "    # Hint 3: Sample x_t from p(x_t | x_0)\n",
        "    x0_onehot = F.one_hot(x_0, num_classes=K).float()  # [B, S, K]\n",
        "    p_xt = torch.einsum('bsk,bkj->bsj', x0_onehot, Q_bar[t])\n",
        "    xt = torch.distributions.Categorical(probs=p_xt).sample()\n",
        "\n",
        "    # TODO: Predict logits of p(x_0 | x_t) using model\n",
        "    # Model outputs logits for each position predicting the original clean token\n",
        "    p_x0 = model(xt, t).transpose(1,2) # [B, S, K] -> [B, K, S]\n",
        "\n",
        "    # TODO: Compute cross-entropy loss between predicted x_0 and true x_0\n",
        "    loss = F.cross_entropy(p_x0, x_0)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e8d8e844",
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_step(model, x_0, time_steps, Q, Q_bar, device):\n",
        "    \"\"\"\n",
        "    Evaluate D3PM model on a single batch and return the loss.\n",
        "\n",
        "    Args:\n",
        "        model: The D3PM model that predicts p(x_0 | x_t)\n",
        "        x_0: Clean discrete tokens from dataset [batch_size, seq_len] (integer values 0 to K-1)\n",
        "        time_steps: Total number of diffusion steps T\n",
        "        Q: Transition matrices for each timestep [T, K, K]\n",
        "        Q_bar: Cumulative transition matrices [T, K, K]\n",
        "        device: Device to run on\n",
        "\n",
        "    Returns:\n",
        "        loss value\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = x_0.shape[0]\n",
        "    K = Q_bar.shape[-1]\n",
        "\n",
        "    # Sample a batch of random timesteps t ~ Uniform(1, T)\n",
        "    t = torch.randint(1, time_steps, (batch_size,), device=device)\n",
        "\n",
        "    # Compute corrupted tokens x_t by sampling from categorical distribution\n",
        "    # p(x_t | x_0) = x_0 @ Q_bar_t (one-hot x_0 times transition matrix)\n",
        "    x0_onehot = F.one_hot(x_0, num_classes=K).float()  # [B, S, K]\n",
        "    Q_bar_t = Q_bar[t]  # [B, K, K]\n",
        "    p_x_t = torch.einsum('bsk,bkj->bsj', x0_onehot, Q_bar_t)  # [B, S, K]\n",
        "    x_t = torch.distributions.Categorical(probs=p_x_t).sample()\n",
        "\n",
        "    # Predict p(x_0 | x_t) using model\n",
        "    with torch.no_grad():\n",
        "        logits_p_x_0 = model(x_t, t)\n",
        "\n",
        "    # Compute cross-entropy loss between predicted x_0 and true x_0\n",
        "    loss = F.cross_entropy(logits_p_x_0.transpose(1, 2), x_0)\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52ebfa73",
      "metadata": {},
      "source": [
        "  **Inference Steps for D3PM:**\n",
        "  \n",
        "  1. Start with $x_{t_{start}}$:\n",
        "     - If starting from pure noise ($t_{start} = T$): $x_T \\sim \\text{Uniform}(1, K)$\n",
        "     - If starting from partially noised data: provide $x_{t_{start}}$ directly\n",
        "  2. For $t = t_{start}, t_{start}-1, \\ldots, 1$:\n",
        "     - Predict $\\pi_i = p_\\theta(x_0 = i | x_t, t)$ using the neural network\n",
        "     - Compute conditional posterior: $q(x_{t-1}=k | x_t=j, x_0=i) = \\frac{Q_t[k,j] \\cdot \\bar{Q}_{t-1}[i,k]}{\\bar{Q}_t[i,j]}$\n",
        "     - Marginalize: $p_\\theta(x_{t-1}=k | x_t=j) = \\sum_{i=1}^K \\pi_i \\cdot q(x_{t-1}=k | x_t=j, x_0=i)$\n",
        "     - Sample $x_{t-1} \\sim p_\\theta(x_{t-1} | x_t)$\n",
        "  3. Return $x_0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e3062d7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample_d3pm(\n",
        "    model,\n",
        "    Q,\n",
        "    Q_bar,\n",
        "    device,\n",
        "    init_probs,               # [K] initial probability distribution (defined upstream)\n",
        "    *,\n",
        "    x_t=None,                 # [B,S] int\n",
        "    t_start=None,             # int\n",
        "    shape=None,               # (B,S) if x_t is None\n",
        "    return_intermediates=False,\n",
        "    intermediate_steps=None,\n",
        "    eps=1e-10,\n",
        "):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    Q = Q.to(device=device)\n",
        "    Q_bar = Q_bar.to(device=device)\n",
        "    init_probs = init_probs.to(device=device)\n",
        "\n",
        "    T = int(Q.shape[0])\n",
        "    K = int(Q.shape[-1])\n",
        "\n",
        "    if x_t is None:\n",
        "        if shape is None:\n",
        "            raise ValueError(\"Provide shape=(B,S) when x_t is None.\")\n",
        "        t_start = T - 1 if t_start is None else int(t_start)\n",
        "        x_t = torch.distributions.Categorical(probs=init_probs).sample(shape)\n",
        "    else:\n",
        "        x_t = x_t.to(device=device)\n",
        "        if t_start is None:\n",
        "            raise ValueError(\"Provide t_start when x_t is given.\")\n",
        "        t_start = int(t_start)\n",
        "\n",
        "    if not (0 <= t_start < T):\n",
        "        raise ValueError(f\"t_start must be in [0, {T-1}], got {t_start}.\")\n",
        "\n",
        "    B = int(x_t.shape[0])\n",
        "\n",
        "    if return_intermediates:\n",
        "        steps = [] if intermediate_steps is None else list(intermediate_steps)\n",
        "        step_set = set(steps)\n",
        "        x0_by_step = {}\n",
        "        x_tm1_by_step = {}\n",
        "\n",
        "    for t in reversed(range(1, t_start + 1)):\n",
        "        t_batch = torch.full((B,), t, dtype=torch.long, device=device)\n",
        "\n",
        "        # TODO: Get model prediction for p(x_0 | x_t)\n",
        "        logits_p_x_0 = model(x_t, t_batch) # [B, S, K]\n",
        "        pi = F.softmax(logits_p_x_0, dim=-1)                # [B,S,K] softmax over logits\n",
        "\n",
        "        # TODO: Get transition matrices for current timestep\n",
        "        # Q_t = ...      # [K,K]  (k -> j)\n",
        "        Q_t = Q[t]\n",
        "        # Qbar_t = ...   # [K,K]  (i -> j)\n",
        "        Q_bar_t = Q_bar[t]\n",
        "        # Qbar_tm1 = ... # [K,K]  (i -> k)\n",
        "        Q_bar_tm1 = Q_bar[t - 1]\n",
        "\n",
        "        # TODO: Compute posterior q(x_{t-1}=k | x_t=j, x_0=i)\n",
        "        # for b in range(B):\n",
        "        #     for s in range(S):\n",
        "        #         j = x_t[b,s] # x_t\n",
        "        #         for i in range(K): # x_0\n",
        "        #             for k in range(K): # x_{t-1}\n",
        "        #                 posterior[b,s,i,k] = Q_t[k,j] * Q_bar_tm1[i,k] / Q_bar_t[i,j]\n",
        "\n",
        "        # Vectorized computation of posterior q(x_{t-1}=k | x_t=j, x_0=i)\n",
        "        # x_t: [B, S] -> j indices\n",
        "        # Q_t[k, j]: transition from k to j at time t\n",
        "        # Q_bar_tm1[i, k]: cumulative transition from i to k at time t-1\n",
        "        # Q_bar_t[i, j]: cumulative transition from i to j at time t\n",
        "        \n",
        "        j = x_t  # [B, S]\n",
        "        Q_t_kj = Q_t[:, j]  # [K, B, S] -> Q_t[k, x_t[b,s]]\n",
        "        Q_bar_t_ij = Q_bar_t[:, j]  # [K, B, S] -> Q_bar_t[i, x_t[b,s]]\n",
        "        \n",
        "        # posterior[b,s,i,k] = Q_t[k, j] * Q_bar_tm1[i, k] / Q_bar_t[i, j]\n",
        "        # Q_t_kj: [K, B, S] -> need [B, S, 1, K]\n",
        "        # Q_bar_tm1: [K, K] (i, k) -> need [1, 1, K, K]\n",
        "        # Q_bar_t_ij: [K, B, S] -> need [B, S, K, 1]\n",
        "        \n",
        "        Q_t_kj = Q_t_kj.permute(1, 2, 0).unsqueeze(2)  # [B, S, 1, K]\n",
        "        Q_bar_t_ij = Q_bar_t_ij.permute(1, 2, 0).unsqueeze(-1)  # [B, S, K, 1]\n",
        "        Q_bar_tm1_ik = Q_bar_tm1.unsqueeze(0).unsqueeze(0)  # [1, 1, K, K]\n",
        "        \n",
        "        posterior = Q_t_kj * Q_bar_tm1_ik / (Q_bar_t_ij + eps)  # [B, S, K_x0, K_xtm1]\n",
        "\n",
        "        # TODO: Compute p(x_{t-1} | x_t) by marginalizing over x_0\n",
        "        # full_posterior = torch.empty(B,S,K)\n",
        "        # for b in range(B):\n",
        "        #     for s in range(S):\n",
        "        #         for k in range(K): # x_{t-1}\n",
        "        #             for i in range(K):\n",
        "        #                 full_posterior[b,s,k] = (pi[b,s,i] * posterior[b,s,i,k]).sum()\n",
        "\n",
        "        # Vectorized: pi[b,s,i] * posterior[b,s,i,k] summed over i\n",
        "        # pi: [B, S, K] -> [B, S, K, 1]\n",
        "        # posterior: [B, S, K_x0, K_xtm1] = [B, S, K, K]\n",
        "        full_posterior = (pi.unsqueeze(-1) * posterior).sum(dim=2)  # [B, S, K]\n",
        "\n",
        "        # TODO: Sample x_{t-1} from categorical distribution\n",
        "        x_tm1 = torch.distributions.Categorical(probs=full_posterior).sample()\n",
        "\n",
        "        if return_intermediates and t in step_set:\n",
        "            x0_by_step[t] = pi.argmax(dim=-1).detach().clone()\n",
        "            x_tm1_by_step[t] = x_tm1.detach().clone()\n",
        "\n",
        "        x_t = x_tm1\n",
        "\n",
        "    if return_intermediates and 0 in step_set:\n",
        "        x0_by_step[0] = x_t.detach().clone()\n",
        "        x_tm1_by_step[0] = x_t.detach().clone()\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "\n",
        "    if return_intermediates:\n",
        "        x0s = [x0_by_step[t] for t in steps]\n",
        "        x_tm1s = [x_tm1_by_step[t] for t in steps]\n",
        "        return x_t, x0s, x_tm1s\n",
        "\n",
        "    return x_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cb37034b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "_chars = list(\"abcdefghijklmnopqrstuvwxyz \")\n",
        "_idx_to_char = {i: c for i, c in enumerate(_chars)}\n",
        "\n",
        "\n",
        "def _tokens_to_str(tokens):\n",
        "    return ''.join(_idx_to_char.get(int(t), '?') for t in tokens.cpu())\n",
        "\n",
        "\n",
        "def visualize_generation_samples(model, sample_fn, time_steps, epoch, n=5, seed=None):\n",
        "    \"\"\"Print n texts generated from pure noise.\"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        samples = sample_fn(model, n, time_steps)\n",
        "    print(f\"=== Generated Samples | Epoch {epoch} ===\")\n",
        "    for i, seq in enumerate(samples):\n",
        "        print(f\"  [{i+1}] {_tokens_to_str(seq)}\")\n",
        "\n",
        "\n",
        "def visualize_generation_timeline(model, sample_fn, time_steps, epoch, k=8, seed=None):\n",
        "    \"\"\"Print pred_x0 and x_{t-1} at k evenly-spaced denoising steps (T -> 0).\"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    steps = sorted(set(np.linspace(0, time_steps - 1, k, dtype=int).tolist()), reverse=True)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x0s, x_tm1s = sample_fn(\n",
        "            model, 1, time_steps,\n",
        "            return_intermediates=True,\n",
        "            intermediate_steps=steps,\n",
        "        )\n",
        "    pad = len(str(time_steps - 1))\n",
        "    print(f\"=== Generation Timeline | Epoch {epoch} ===\")\n",
        "    for t, x0, x_tm1 in zip(steps, x0s, x_tm1s):\n",
        "        print(f\"  t={t:{pad}d}/{time_steps-1} | pred_x0: {_tokens_to_str(x0[0])}\")\n",
        "        print(f\"  {' ' * (pad + 2 + len(str(time_steps-1)))}  | x_{{t-1}}: {_tokens_to_str(x_tm1[0])}\")\n",
        "\n",
        "\n",
        "def visualize_reconstruction_samples(\n",
        "    model, sample_fn, Q_bar, time_steps, epoch, k=5, seed=None, dataset=None, t_noise=125\n",
        "):\n",
        "    \"\"\"Print (original, noised, denoised) triplets for k dataset samples.\"\"\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    indices = torch.randperm(len(dataset))[:k]\n",
        "    x0 = torch.stack([dataset[i][0] for i in indices]).long()\n",
        "    device = Q_bar.device\n",
        "    K = Q_bar.shape[-1]\n",
        "    x0 = x0.to(device)\n",
        "    if x0.ndim > 2:\n",
        "        x0 = x0.view(k, -1)\n",
        "    t = min(t_noise, time_steps - 1)\n",
        "    x0_onehot = F.one_hot(x0, num_classes=K).float()\n",
        "    p_xt = torch.einsum('bsk,bkj->bsj', x0_onehot, Q_bar[t].unsqueeze(0).expand(k, -1, -1))\n",
        "    x_noised = torch.distributions.Categorical(probs=p_xt).sample()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        denoised = sample_fn(model, k, t + 1, x_init=x_noised)\n",
        "    print(f\"=== Reconstruction Samples | Epoch {epoch} | t_noise={t} ===\")\n",
        "    for i in range(k):\n",
        "        print(f\"  [{i+1}] original : {_tokens_to_str(x0[i])}\")\n",
        "        print(f\"  [{i+1}] noised   : {_tokens_to_str(x_noised[i])}\")\n",
        "        print(f\"  [{i+1}] denoised : {_tokens_to_str(denoised[i])}\")\n",
        "        if i < k - 1:\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "14754280",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    return \"cpu\"\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    num_epochs,\n",
        "    learning_rate,\n",
        "    time_steps,\n",
        "    schedule_fn,\n",
        "    transition_kernel_fn,\n",
        "    *,\n",
        "    recon_t_noise=125,\n",
        "    refresh_every_k_epochs=5,\n",
        "):\n",
        "\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "\n",
        "    betas, _, _ = schedule_fn(time_steps)\n",
        "    betas = torch.as_tensor(betas, device=device, dtype=torch.float32)\n",
        "\n",
        "    x0_example, = next(iter(train_dataloader))\n",
        "    x0_example = x0_example.to(device)\n",
        "    S = int(x0_example.shape[1]) if x0_example.ndim == 2 else int(np.prod(x0_example.shape[1:]))\n",
        "    K = getattr(train_dataloader.dataset, \"K\", None)\n",
        "    if K is None:\n",
        "        K = int(x0_example.max().item()) + 1\n",
        "    K = int(K)\n",
        "\n",
        "    I = torch.eye(K, device=device, dtype=torch.float32)\n",
        "    Q = torch.empty((time_steps, K, K), device=device, dtype=torch.float32)\n",
        "    Q_bar = torch.empty_like(Q)\n",
        "    Q[0] = I\n",
        "    Q_bar[0] = I\n",
        "\n",
        "    init_probs = None\n",
        "    for t in range(1, time_steps):\n",
        "        Q_t, pi = transition_kernel_fn(float(betas[t].item()), K)\n",
        "        Q_t = torch.as_tensor(Q_t, device=device, dtype=torch.float32)\n",
        "        Q[t] = Q_t\n",
        "        Q_bar[t] = Q_bar[t - 1] @ Q_t\n",
        "        if init_probs is None:\n",
        "            init_probs = torch.as_tensor(pi, device=device, dtype=torch.float32)\n",
        "\n",
        "    if init_probs is None:\n",
        "        init_probs = torch.full((K,), 1.0 / K, device=device, dtype=torch.float32)\n",
        "\n",
        "    def sample_fn(model, n_samples, num_steps, *, x_init=None, return_intermediates=False, intermediate_steps=None):\n",
        "        if x_init is None:\n",
        "            out = sample_d3pm(\n",
        "                model, Q, Q_bar, device, init_probs,\n",
        "                shape=(n_samples, S),\n",
        "                t_start=num_steps - 1,\n",
        "                return_intermediates=return_intermediates,\n",
        "                intermediate_steps=intermediate_steps,\n",
        "            )\n",
        "        else:\n",
        "            x_t = x_init.view(-1, S).long().to(device)\n",
        "            out = sample_d3pm(\n",
        "                model, Q, Q_bar, device, init_probs,\n",
        "                x_t=x_t,\n",
        "                t_start=num_steps - 1,\n",
        "                return_intermediates=return_intermediates,\n",
        "                intermediate_steps=intermediate_steps,\n",
        "            )\n",
        "        if return_intermediates:\n",
        "            _, x0s, x_tm1s = out\n",
        "            return x0s, x_tm1s\n",
        "        return out\n",
        "\n",
        "    num_params = sum(p.numel() for p in model.parameters())\n",
        "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model_class_name = model.__class__.__name__\n",
        "    model_dir = f\"data/experiments/text8/{model_class_name}\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Model: {model_class_name} | Params: {num_params:,} (trainable: {num_trainable_params:,})\")\n",
        "    model.eval()\n",
        "    visualize_generation_samples(model, sample_fn, time_steps, epoch=-1, seed=42)\n",
        "    visualize_generation_timeline(model, sample_fn, time_steps, epoch=-1, seed=42)\n",
        "    visualize_reconstruction_samples(\n",
        "        model, sample_fn, Q_bar, time_steps, epoch=-1, k=5, seed=42,\n",
        "        dataset=train_dataloader.dataset,\n",
        "        t_noise=min(int(recon_t_noise), time_steps - 1),\n",
        "    )\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "        epoch_start_time = time.time()\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        model.train()\n",
        "        for x_0, in tqdm(train_dataloader, desc=f\"Epoch {epoch} Train\", leave=False):\n",
        "            x_0 = x_0.to(device)\n",
        "            if x_0.ndim > 2:\n",
        "                x_0 = x_0.view(x_0.shape[0], -1)\n",
        "            loss = train_step(model, x_0.long(), optimizer, time_steps, Q, Q_bar, device)\n",
        "            total_loss += loss\n",
        "            num_batches += 1\n",
        "\n",
        "        avg_train_loss = total_loss / max(num_batches, 1)\n",
        "\n",
        "        model.eval()\n",
        "        total_test_loss = 0\n",
        "        num_test_batches = 0\n",
        "        with torch.no_grad():\n",
        "            for x_0, in tqdm(test_dataloader, desc=f\"Epoch {epoch} Test\", leave=False):\n",
        "                x_0 = x_0.to(device)\n",
        "                if x_0.ndim > 2:\n",
        "                    x_0 = x_0.view(x_0.shape[0], -1)\n",
        "                test_loss = eval_step(model, x_0.long(), time_steps, Q, Q_bar, device)\n",
        "                total_test_loss += test_loss\n",
        "                num_test_batches += 1\n",
        "\n",
        "        avg_test_loss = total_test_loss / max(num_test_batches, 1)\n",
        "        epoch_train_time = time.time() - epoch_start_time\n",
        "\n",
        "        torch.save(model.state_dict(), f\"{model_dir}/model_latest.pth\")\n",
        "\n",
        "        should_refresh = (\n",
        "            refresh_every_k_epochs > 0\n",
        "            and ((epoch + 1) % refresh_every_k_epochs == 0 or epoch == num_epochs - 1)\n",
        "        )\n",
        "\n",
        "        if should_refresh:\n",
        "            clear_output(wait=True)\n",
        "        print(f\"Model: {model_class_name} | Params: {num_params:,} (trainable: {num_trainable_params:,})\")\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{num_epochs-1} | \"\n",
        "            f\"Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f} | \"\n",
        "            f\"Time: {epoch_train_time:.2f}s\"\n",
        "        )\n",
        "\n",
        "        if should_refresh:\n",
        "            visualize_generation_samples(model, sample_fn, time_steps, epoch, seed=42)\n",
        "            visualize_generation_timeline(model, sample_fn, time_steps, epoch, k=8, seed=42)\n",
        "            visualize_reconstruction_samples(\n",
        "                model, sample_fn, Q_bar, time_steps, epoch, k=5, seed=42,\n",
        "                dataset=train_dataloader.dataset,\n",
        "                t_noise=min(int(recon_t_noise), time_steps - 1),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5feb0eaf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batches: 5494\n",
            "Test batches: 611\n",
            "Model: DDiT_Llama | Params: 7,769,627 (trainable: 7,769,627)\n",
            "=== Generated Samples | Epoch -1 ===\n",
            "  [1] soujbhelureuyalhpllzsjnpinaqdbjpwdtjwsftxsbasrjjsedvavoshjxbdjvynucuwlafwihcbfjtrlakqmwmyfghweoyoxxgwahxoqhcswljgomjujbslmfrvrmdzklwrmvglqrvuiqvaxaqxgvpaqwqoypfutgiemccisgxsdpfvxrrrwysmchvofxtesqeslktvyigsdwzpaemyykmgdmfojvxibbogbwfsglgkxcqvufpkjqjinsejnqk\n",
            "  [2] zeoagiwcghgxhhsstfuivanhgcnszkynghkjyamaewbcgevkaezsedbzwagtcbsjxnmxzdkanyjtorgaucfxhwhjpynmjggwxgnaozwdrzlmtkdxskbhhckgbllihovnmfrieepqypxwefdsguyoufwsqjnxjinucqirsynobzuyxecnpuzvzzttbmgmatrpdojbbajygaiytoaddtazsrvmlzluoecvaqyoeisbgqfugufzcgdsntitvfrbpmpd\n",
            "  [3] ufyxwwnygjwilddujasjqnzqryauxdfkjbvifrzgtkzfpexjruayikmpcrqfzzqtqksxuogsnznfmrvjbusmfdoaqzsjjinpecmnycloamevzealzsapwqhaplxazfherqfypblsiwqqzivofemvtfyaawjubmeptwmlildullddtyamomuuffqcbegcnftqkypjaldpzbcohzcfmfklebqslhtzgmhfovuyxqmobabfdnrhflgoxtfmarhhfgzm\n",
            "  [4] bvqnmyfvuxqpypvxsxjoafvdggauathyhqtdecfmfgcnmairtrenurihzdfcuiknureivwhfpclnenupvhvrdghwdvuaokpfjrhwspgaestnqqifhltmwziixajtiariqshnqiwdduomdjfilpgmlpzxyxkxlqawrosomhzdnafgaaildndvwdyzotaixfzhaarylghrvvkfojdkyhattgixqwltucapmbzjtezwpuvfbusykazmyahcikgtpfxt\n",
            "  [5] ikqnlapqvsynpjpfvlsudohimsiioqjtyxeciojkafxkaeoocdmbgvyrmrrjnreahrjueptyaoqlqwghrluhtvvmzwybmccmpuaqahhhwgdmdjunntrdwynkjjzeurpqcmlfdjdzvdqzhsajzlqvuvnylxbbpbsoqnxulpmbphhmtxkvqzkyskqjnldlzzijdaxlwsycljqygyzixlivhfacmnsjjzyqzclkovkhnycxtxhlwdtjegjmzxvezkbr\n",
            "=== Generation Timeline | Epoch -1 ===\n",
            "  t=999/999 | pred_x0:                                                                                                                                                                                                                                                                 \n",
            "            | x_{t-1}:                                                                                                                                                                                                                                                                 \n",
            "  t=856/999 | pred_x0:               l                                                                                                  o                  r                          f    e           v           o                       y    d                                      \n",
            "            | x_{t-1}:               l                                                                                                  o                  r                          f    e           v           o                       y    d                                      \n",
            "  t=713/999 | pred_x0:             y l    z   p n q        w     b      e                    a              m       e   x   a x     wl  o   jb        d    r    q    q         a   o  f    e           v      s    o          t  i      a  yy   d         o b    lg     u            qk\n",
            "            | x_{t-1}:             y l    z   p n q        w     b      e                    a              m       e   x   a x     wl  o   jb        d    r    q    q         a   o  f    e           v      s    o          t  i      a  yy   d         o b    lg     u            qk\n",
            "  t=570/999 | pred_x0:    jb elu e yal    zs  p n qd j    jw   xsb   j  ed a   h x       c  la  ih bf    ak mw  f  we yox   a x  h  wlj o  ujb    r   d k  r    q    q         a w o  f t  e    s   d  v    w s    of   s     t  ig  w  a  yy   d     xi  ogb  s lgkx   u  k    ns   qk\n",
            "            | x_{t-1}:    jb elu e yal    zs  p n qd j    jw   xsb   j  ed a   h x       c  la  ih bf    ak mw  f  we yox   a x  h  wlj o  ujb    r   d k  r    q    q         a w o  f t  e    s   d  v    w s    of   s     t  ig  w  a  yy   d     xi  ogb  s lgkx   u  k    ns   qk\n",
            "  t=428/999 | pred_x0:   ujb elu e yal p lzs npin qd j    jwsftxsbas jj edvavo hjx  jvy  cuwla  ih bf t  akqmw yf  we yoxxg a x  h  wlj omjujb    r  mdzk wrmv  q    q   a x   a w o pf tgie    sgxsd  v r  wys ch of   s e  kt  ig  wzpae yyk  d    vxi bogb fs lgkxcq u pkj   nsej qk\n",
            "            | x_{t-1}:   ujb elu e yal p lzs npin qd j    jwsftxsbas jj edvavo hjx  jvy  cuwla  ih bf t  akqmw yf  we yoxxg a x  h  wlj omjujb    r  mdzk wrmv  q    q   a x   a w o pf tgie    sgxsd  v r  wys ch of   s e  kt  ig  wzpae yyk  d    vxi bogb fs lgkxcq u pkj   nsej qk\n",
            "  t=285/999 | pred_x0: soujb elu euyalhp lzs npin qd jpw  jwsftxsbasrjj edvavoshjxb jvy ucuwlafwihcbf t  akqmw yfg weoyoxxg ahxoqh swlj omjujbsl frv mdzk wrmvg qr  iq axa x   a w o pfutgie c isgxsdp v rr wys ch ofxt s e lkt  igs wzpaemyykmgd  o vxi bogbwfsglgkxcqvu pkj   nsej qk\n",
            "            | x_{t-1}: soujb elu euyalhp lzs npin qd jpw  jwsftxsbasrjj edvavoshjxb jvy ucuwlafwihcbf t  akqmw yfg weoyoxxg ahxoqh swlj omjujbsl frv mdzk wrmvg qr  iq axa x   a w o pfutgie c isgxsdp v rr wys ch ofxt s e lkt  igs wzpaemyykmgd  o vxi bogbwfsglgkxcqvu pkj   nsej qk\n",
            "  t=142/999 | pred_x0: soujb elu euyalhpllzsjnpinaqd jpwdtjwsftxsbasrjjsedvavoshjxb jvy ucuwlafwihcbfjtrlakqmwmyfghweoyoxxgwahxoqhcswljgomjujbslmfrvrmdzk wrmvg qr  iq axa x vpa wqo pfutgiemccisgxsdpfvxrrrwysmch ofxtes eslktvyigs wzpaemyykmgd fo vxibbogbwfsglgkxcqvufpkjqjinsej qk\n",
            "            | x_{t-1}: soujb elu euyalhpllzsjnpinaqd jpwdtjwsftxsbasrjjsedvavoshjxb jvy ucuwlafwihcbfjtrlakqmwmyfghweoyoxxgwahxoqhcswljgomjujbslmfrvrmdzk wrmvg qr  iq axa x vpa wqoypfutgiemccisgxsdpfvxrrrwysmch ofxtes eslktvyigs wzpaemyykmgd fo vxibbogbwfsglgkxcqvufpkjqjinsej qk\n",
            "  t=  0/999 | pred_x0: soujbhelureuyalhpllzsjnpinaqdbjpwdtjwsftxsbasrjjsedvavoshjxbdjvynucuwlafwihcbfjtrlakqmwmyfghweoyoxxgwahxoqhcswljgomjujbslmfrvrmdzklwrmvglqrvuiqvaxaqxgvpaqwqoypfutgiemccisgxsdpfvxrrrwysmchvofxtesqeslktvyigsdwzpaemyykmgdmfojvxibbogbwfsglgkxcqvufpkjqjinsejnqk\n",
            "            | x_{t-1}: soujbhelureuyalhpllzsjnpinaqdbjpwdtjwsftxsbasrjjsedvavoshjxbdjvynucuwlafwihcbfjtrlakqmwmyfghweoyoxxgwahxoqhcswljgomjujbslmfrvrmdzklwrmvglqrvuiqvaxaqxgvpaqwqoypfutgiemccisgxsdpfvxrrrwysmchvofxtesqeslktvyigsdwzpaemyykmgdmfojvxibbogbwfsglgkxcqvufpkjqjinsejnqk\n",
            "=== Reconstruction Samples | Epoch -1 | t_noise=125 ===\n",
            "  [1] original : nish territory many flemish fled to holland among them half of the population of antwerp three four of brugge and ghent and the entire population of nieuwpoort dunkerque and countryside the war dragged on for another six zero years but the main fighting wa\n",
            "  [1] noised   : nish ter i ory  any flemi h fled to holland among them half of the population of antw rp three four of brugge and ghent and the entire population of nieu poort d nkerqu  an  countryside  he war dragged on for another six zero year  but the main fighting wa\n",
            "  [1] denoised : nishpterlinorynbanypflemiahgfledetorhollandeamongythemvhalfzoftthenpopulationeofyantwjrpethreegfouraofrbruggebandbghentnandstheventirehpopulationzoffnieuspoortydunkerqusxanzfcountrysidecfheewarvdraggeduonzforbanotherasixuzerozyearolbutfthehmainbfightingkwa\n",
            "\n",
            "  [2] original : nary files necessary for local hashing some disadvantages cited by critics include slow reactions to patches a longer time to connect compared to local hashing and occasional server downtime also some bot users are uncomfortable sending their cd keys and p\n",
            "  [2] noised   :  ary files necessary for local hashing some disadvantages cited by critics include slow reactions to patch s a longer ti e to connect compared to local has ing and occasional  erver  owntime  lso some bot users are uncomfortable  ending their cd keys and p\n",
            "  [2] denoised : jaryffilesbnecessaryaforclocalahashingosomepdisadvantagesccitedvbyscriticsrincludeaslowhreactionsgtoapatchlscaflongerltioeitoxconnecticomparedetoflocalihasringrandooccasionalvlerverqdowntimebhlsowsomepbotausersearewuncomfortableyxendingmtheirncdfkeysfandtp\n",
            "\n",
            "  [3] original : entertainment including the record industry music industry radio television and movies news media leisure industry transport healthcare consulting investment and legal advice and services public utilities are often considered part of the tertiary sector as\n",
            "  [3] noised   : ent rtai ment including the record in ustry m sic indu try radio television  nd movies news media  eisure industry transport healthcare consulting i vestm nt and lega  advice and se vices public utilities are often considere  part of the  ertiary sector as\n",
            "  [3] denoised : entwrtaipmentjincludingwthedrecordbinlustrytmjsicxinduztryhradiootelevisionflndbmovieshnewspmediauqeisurefindustryhtransportohealthcarenconsultingyinvestmqntaandulegahzadvicexandrsewviceszpublictutilitiesfareuoftenhconsidereigpartuofnthexvertiaryqsectorvas\n",
            "\n",
            "  [4] original : when andre was five years old he was already practicing with pros such as jimmy connors and roscoe tanner mike agassi learned tennis by watching tapes of champions mike agassi took a very systematic approach to the physics and psychology of tennis and stil\n",
            "  [4] noised   : when andre w s five years old he w s already practicing wit  pros such as jimmy c nnors and roscoe tanner mike agassi learned tenn s by watching t pes of champions mike agassi took a very systematic approach to the physics and psychology of tennis and stil\n",
            "  [4] denoised : whenqandrenwssjfivewyearsqoldyhepwmssalreadyupracticingmwithiprosdsucheasqjimmygcwnnorsoandhroscoeutannerwmikekagassiulearnedntennzssbykwatchingotnpesvoftchampionsmmikekagassiwtookraxverygsystematicnapproachstoutherphysicsjandmpsychologybofktennisbandfstil\n",
            "\n",
            "  [5] original : rts leisure centers one nine screen cinema a factory outlet shopping center called the galleria situated above the a one m and two supermarkets asda in the town centre and tesco at the northern end of the town hatfield is most famous for being the location\n",
            "  [5] noised   :  ts leisure centers one nine scr en cinema a factory outlet s opping center call d the galleria situated above the a one m and two supermark ts asda in the to n centre and tesco a  the nor he n end of t e town  atfield is most famous for being the location\n",
            "  [5] denoised : ttsxleisurepcentersxonefninenscrmenlcinemaeasfactoryboutletlsqoppingycentericallqdbthehgalleriaisituatedvaboventhedazonezmyandztwoksupermarkltsuasdaxinatheatonnicentrefandktescojaduthejnorbheoncendwofjtpextowntuatfieldbislmosttfamousqforxbeingsthedlocation\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs:   0%|          | 0/100 [01:52<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m TRANSITION_KERNEL_FN = absorbing_kernel\n\u001b[32m     15\u001b[39m RECON_T_NOISE = \u001b[32m125\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTIME_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSCHEDULE_FN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransition_kernel_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTRANSITION_KERNEL_FN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecon_t_noise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRECON_T_NOISE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dataloader, test_dataloader, num_epochs, learning_rate, time_steps, schedule_fn, transition_kernel_fn, recon_t_noise)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x_0.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    102\u001b[39m     x_0 = x_0.view(x_0.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m total_loss += loss\n\u001b[32m    105\u001b[39m num_batches += \u001b[32m1\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, x_0, optimizer, time_steps, Q, Q_bar, device)\u001b[39m\n\u001b[32m     43\u001b[39m loss = F.cross_entropy(p_x0, x_0)\n\u001b[32m     45\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:526\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    521\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    522\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    523\u001b[39m             )\n\u001b[32m    525\u001b[39m \u001b[38;5;66;03m# pyrefly: ignore [invalid-param-spec]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/adam.py:248\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    236\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    238\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    239\u001b[39m         group,\n\u001b[32m    240\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    245\u001b[39m         state_steps,\n\u001b[32m    246\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:151\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/adam.py:970\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    967\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    968\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/deep-learning-course-2026/.venv/lib/python3.12/site-packages/torch/optim/adam.py:547\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    545\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-4\n",
        "TIME_STEPS = 256\n",
        "SCHEDULE_FN = cosine_schedule\n",
        "TRANSITION_KERNEL_FN = absorbing_kernel\n",
        "RECON_T_NOISE = 125\n",
        "REFRESH_EVERY_K_EPOCHS = 5\n",
        "\n",
        "train(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    test_dataloader,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    time_steps=TIME_STEPS,\n",
        "    schedule_fn=SCHEDULE_FN,\n",
        "    transition_kernel_fn=TRANSITION_KERNEL_FN,\n",
        "    recon_t_noise=RECON_T_NOISE,\n",
        "    refresh_every_k_epochs=REFRESH_EVERY_K_EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d979b820",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
